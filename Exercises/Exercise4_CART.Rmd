---
title: "Exercise 4"
author: "Nilima Ajaikumar, Hagay Jalon & Gian Zlupko"
date: "2022-11-14"
output: html_document
---

```{r message = FALSE, warning = FALSE}
library(tidyverse) 
library(xlsx) 
library(pROC) 
library(OptimalCutpoints) # for dealing with cutoff point
library(naniar) # replaces missing data to NA
```


# Part I: NECS Data 

For the first part of our Exercise 4, we are recreating the figures and tables published in Bowers & Zhou (2019). Our code and results for this section are organized as follows. First, we load and clean the NCES data. Then, we provide the code, documentation, and interpretation for Tables 1-3 and Figures 1-3 from Bowers & Zhou (2019) in the order in which they appear in the article. 

#### Import Data 

The following steps were implemented to access data from NCES' online repository. 


```{r}
setwd("/Users/gianzlupko/Desktop/ORLA 6541 Data Science/ORLA_6541_Applied_Data_Science/NCES_Data") 

# Load R Data File
load("els_full_data.rdata")

# simplify name of data frame 
els_full_data <- els_02_12_byf3pststu_v1_0


# variables that we would like to keep 

keepvars <- c(
   "STU_ID",
   "F2EVERDO", # Dropout
   "BYP52E", # Absent*
   "BYS24F", # Suspension*
   "BYP51", # Misbehavior*
   "BYTXMSTD", # Math t score (2002) - lowercase in the data
   "BYS42", # Extracurricular activities (2002) hours/wk
   "BYTXRSTD", # Reading t score (2002)* - lowercase in the data
   "F2PS0601", # College enrollment
   "F1RGPP2", # GPA
   "F1S27", # Extracurricular activities (2004) hours/wk
   "BYS33A", # AP
   "F3TZSTEM1CRED", # Postsecondary STEM degree
   "F3TZSTEM1TOT", # Number of STEM Courses
   "F3TZSTEM2GPA", # STEM course GPA
   "F3STEMOCCCUR" # Hard STEM career
)

# select subset of variables that were used in Bowers & Zhou (2019)
# also apply renaming to make the data readable 
els_clean <- els_full_data %>% 
  select(STU_ID, F2EVERDO, BYP52E, BYS24F, BYP51, bytxmstd, BYS42, bytxrstd,
         F2PS0601, F1RGPP2, F1S27, BYS33A, F3TZSTEM1CRED, F3TZSTEM1TOT,
         F3TZSTEM2GPA, F3STEMOCCCUR) %>%
  rename(student_ID = STU_ID, drop_out = F2EVERDO, absent = BYP52E, suspension = BYS24F, 
         misbehavior = BYP51, math_tscore = bytxmstd, extra_curr_2002 = BYS42, 
         reading_tscore = bytxrstd, college_enroll = F2PS0601, GPA = F1RGPP2, extra_curr_2004 = F1S27, AP = BYS33A, post_sec_stem = F3TZSTEM1CRED, no_stem_courses = F3TZSTEM1TOT, stem_GPA = F3TZSTEM2GPA, hard_stem_career = F3STEMOCCCUR)   

# inspect cleaning 
els_clean


# finally, create the feature engineered flags that Bowers & Zhou also tested to look at 
# the impact of the potential implication of one or more 'flags' or common indicators of 
# student drop out 
# the flags include: absent, suspension math_tscore in the 1st percentile, and misbehavior 

els_vars <- els_clean %>%
  mutate(flag_00 = ifelse(rowSums(select(., c(3:6)), na.rm = T) >= 1, 1, 0), 
         flag_01 = ifelse(absent == 1 | suspension == 1 | math_tscore == 1 | misbehavior == 1, 1,0), flag_04 = ifelse(absent == 1 & suspension == 1 & math_tscore == 1 & misbehavior == 1, 1, 0))

```

Remove missing data in the data set that are stored as -9, -8, -4, -1

```{r}
library(naniar)
els_complete <- replace_with_na_if(els_vars,
                                   .predicate = is.numeric,
                                   condition = ~.x < 0)

# Create the math t-score variable following Bowers' CART markdown 

els_complete <- els_complete %>% 
  mutate(math_t_score = ifelse(math_tscore < 44.065, 1, 0), 
         reading_t_score = ifelse(reading_tscore < 43.64, 1, 0))


# finally, view summary of clean variables 
summary(els_complete) 
```


Following Bowers & Zhou (2019), the first table that we create below is Figure 1, which presents a confusion table that specifies common metrics used in machine learning to evaluate prediction performance. 



### Table 1: Confusion Table for Calculating Contingency Proportions 


```{r}

fig_1_stats <- c("Accuracy", "Precision", "Sensitivity (Recall / True-positive Proportion",
                  "Specificity (True-negative Proportion", "1-Specificity (False-positive Proportion", "Kapp")

fig_1_equations <- c("(a + d) / N", 
                     "a / (a + b)", 
                     "a / (a + c)", 
                     "d / (b + d)", 
                     "b / (b + d)", 
                     "(Accuracy - R) / (1 - R)")

# bind columns 
fig_1 <- data.frame(cbind(fig_1_stats, fig_1_equations)) 
colnames(fig_1) <- c("Metric", "Equation")
fig_1

```




### Figures 2A and 2B 

Figure A depicts a ROC plot that utilizes predictors used by Balfanz et al.  (2007) and Figure B uses predictors selected by Bowers & Zhou (2019). 


Figure 2A
```{r, message = FALSE}

# ROC for math t-score
roc1 = roc(els_complete$drop_out, els_complete$math_t_score, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=1, xaxs="i", yaxs="i", main = "ROC curves for predicting dropout")

# ROC for one flag 
roc2 = roc(els_complete$drop_out, els_complete$flag_01, plot=TRUE, add=TRUE, percent=roc1$percent, lty=2)

# ROC for any number of flags 
roc3 = roc(els_complete$drop_out, els_complete$flag_00, plot=TRUE, add=TRUE, percent=roc1$percent, lty=3)

# ROC for all four
roc4 = roc(els_complete$drop_out, els_complete$flag_04, plot=TRUE, add=TRUE, percent=roc1$percent, lty=4)

# ROC for suspension 
roc5 = roc(els_complete$drop_out, els_complete$suspension, plot=TRUE, add=TRUE, percent=roc1$percent, lty=5)

# ROC for misbehavior
roc6 = roc(els_complete$drop_out, els_complete$misbehavior, plot=TRUE, add=TRUE, percent=roc1$percent, lty=6)

# ROC for absent
roc7 = roc(els_complete$drop_out, els_complete$absent, plot=TRUE, add=TRUE, percent=roc1$percent, lty=7)

# legend for the plot 
legend("bottomright", legend=c("Math t score (2002)","Any No. Flags","All Four Flags","Suspension", "Misbehavior", "Absent"), lty=c(1,2,3,4,5,6,7), lwd=2)

```


Figure 2B: 
```{r, message = FALSE}

# ROC for math t-score
roc8 = roc(els_complete$drop_out, els_complete$math_t_score, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=7, xaxs="i", yaxs="i", main = "ROC curves for predicting dropout")

# ROC for reading t score   
roc9 = roc(els_complete$drop_out, els_complete$reading_t_score, plot=TRUE, add=TRUE, percent=roc1$percent, lty=8)

# ROC for absent 
roc10 = roc(els_complete$drop_out, els_complete$absent, plot=TRUE, add=TRUE, percent=roc1$percent, lty=9)

# ROC for suspension 
roc11 = roc(els_complete$drop_out, els_complete$absent, plot=TRUE, add=TRUE, percent=roc1$percent, lty=10)

# ROC for suspension 
roc12 = roc(els_complete$drop_out, els_complete$extra_curr_2002, plot=TRUE, add=TRUE, percent=roc1$percent, lty=11)


# legend for the plot 
legend("bottomright", legend=c("Math t score (2002)", "Reading t score (2002)", "Extrac. activities (2002)", "Absence", "Suspension"), lty=c(7,8,9,10,11), lwd=2)
  
  
```

Figure 2A and 2B depict ROC curves for key variables used to predict high school drop out. All of the predictors in Figure 2B predicted drop out better than chance. This result can be seen by visually inspecting each ROC curve and their distance from the diagonal line in the center of the plot, which indicates a random guess of 0.5. In contrast to Figure 2B, some of the predictors visualized in Figure 2A did not perform better than chance at predicting drop out. In particular, results in Figure 2A demonstrate that any number of flags performed worse than a random guess and all four flags performed about equivalent to a random guess in predictive capacity. 



##### AUC Values Corresponding with Figure 2A and 2B 

Below, we create the data table that is pictured below Figures 2A and 2B in Bowers & Zhou (2019) to show the AUC values that correspond with their respective ROC curves. 

Table under 2A: 
```{r}
# print AUC values and store to a vector
auc_fig2a <- c(roc1$auc, roc2$auc, roc3$auc, roc4$auc, roc5$auc, roc6$auc, roc7$auc) 

# store predictor names in a vector
predictor_fig2a <- c("Math t score (2002)", "Any one flag", "Any number of flags", "All four flags", "Suspension", 
                     "Misbehavior", "Absent")  

# combine vector into a data frame, rename columns, adjust decimal points, and sort desceding by top AUC

fig2a_table <- data.frame(cbind(predictor_fig2a, auc_fig2a)) 
colnames(fig2a_table) <- c("Predictor", "AUC") 

# roundabout convert from factor, have to go through character format first
fig2a_table$AUC <- as.numeric(as.character(fig2a_table$AUC)) 

fig2a_table %>% 
   dplyr::mutate_if(is.numeric, round, 2) 

```

Table under 2B: 
```{r}

# print AUC values and store to a vector
auc_fig2b <- c(roc8$auc, roc9$auc, roc10$auc, roc11$auc, roc12$auc) 

# store predictor names in a vector
predictor_fig2b <- c("Math t score (2002)", "Reading t score (2002)", "Exac. activities (2002)", 
                     "Absence", "Suspension") 

# combine vector into a data frame, rename columns, adjust decimal points, and sort desceding by top AUC

fig2b_table <- data.frame(cbind(predictor_fig2b, auc_fig2b)) 
colnames(fig2b_table) <- c("Predictor", "AUC") 

# roundabout convert from factor, have to go through character format first
fig2b_table$AUC <- as.numeric(as.character(fig2b_table$AUC)) 

fig2b_table %>% 
   dplyr::mutate_if(is.numeric, round, 2) 
```


Results from tables corresponding with Figures 2A and 2B indicated that math t score (2002) was the best predictor of high school drop out. Other predictors that performed well in predicting drop out were absences and involvement in extracurricular activities. 


#### Table 1: Significance of AUC Difference for Predictors of Continuous Dropout 

In our recreation of Table 1 below, we present results from a Delong test of the difference of two correlated ROC curves. Large Z scores and small p-values (below the conventional p < .05) indicate that the area under the respective curves is significantly different. For our table, we compared each predictor to math t score (2002) which was the predictor with the best AUC value observed on the current data. 

```{r}

# custom function to extra Z scores and p-values 
roc_sig_diff <- function(x, y) { 
   
test1 <- roc.test(x,y) 
print(test1$p.value) 
print(test1$statistic) 
   
   }

# cycle through all comparisons needed to build the table: 
roc_sig_diff(roc1, roc2)  
roc_sig_diff(roc1, roc3)  
roc_sig_diff(roc1, roc4)  
roc_sig_diff(roc1, roc5)  
roc_sig_diff(roc1, roc6)  
roc_sig_diff(roc1, roc7)  

# create columns for table 

pred_list_1 <- c("Math t score (2002)", "Math t score (2002)", "Math t score (2002)",
                 "Math t score (2002)", "Math t score (2002)", "Math t score (2002)")  

pred_list_2 <- c("One Flag", "Any number of flags", "All four flags", "Suspension", "Misbehavior", 
                 "Absence")

# create z score column 

z_scores <- c(26.78, 23.85, 23.85, 8.55, 6.45, 0.62)

# create p-value column 
p_values <- c("<.001","<.001", "<.001", "<.001", "0.53", "0.61")


# combine all columns and rename columns 

table_1 <- data.frame(cbind(pred_list_1, pred_list_2, z_scores, p_values)) 
table_1 %>% 
   rename("Predictor 1 " = pred_list_1, "Predictor 2" = pred_list_2, "Z" = z_scores, "p_value" = p_values)
```



Results in Table 1 show that math t score (2002) performed significantly better at predicting dropout than one flag, any number of flags, all four flags, and suspension. In contrast, the results also demonstrated that math t score did not have a significantly different AUC than misbehavior and absence.


### Figure 3: ROC Curves for Predicting College Enrollment and Postsecondary STEM Degree 

Figure 3A
```{r, message = FALSE}

# filter data to only include two values for college enroll: 0 (No), and 1 (Yes)
fig_3_data <- els_complete %>% 
   filter(college_enroll == 1 | college_enroll == 0) 

# ROC curves for GPA, extracurriculars, and AP 5 
# 'roc_enroll'... get it?.... couldn't resist...

roc_enroll_1 = roc(fig_3_data$college_enroll, fig_3_data$GPA, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=12, xaxs="i", yaxs="i", main = "ROC curve for predicting college enrollment - GPA")

roc_enroll_2 = roc(fig_3_data$college_enroll, fig_3_data$extra_curr_2004, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=13, xaxs="i", yaxs="i", main = "ROC curve for predicting college enrollment - Extra Curriculars")


roc_enroll_3 = roc(fig_3_data$college_enroll, fig_3_data$AP, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=14, xaxs="i", yaxs="i", main = "ROC curve for predicting college enrollment - AP")

```

The table below shows the AUC values for each of the ROC curves above: 

```{r}

# print AUC values and store to a vector
auc_fig3a <- c(roc_enroll_1$auc, roc_enroll_2$auc, roc_enroll_3$auc) 

# store predictor names in a vector
predictor_fig3a <- c("GPA", "Extra Curriculars", "AP")     

# combine vector into a data frame, rename columns, adjust decimal points, and sort descending by top AUC

fig3a_table <- data.frame(cbind(predictor_fig3a, auc_fig3a)) 
colnames(fig3a_table) <- c("Predictor", "AUC") 

# roundabout convert from factor, have to go through character format first
fig3a_table$AUC <- as.numeric(as.character(fig3a_table$AUC)) 
fig3a_table %>% 
   dplyr::mutate_if(is.numeric, round, 2) 

```

The AUC values reported in the table indicate that GPA was the best predictor of college enrollment, followed by students' involvement in extra curricular activities. Finally, AP performed only slightly better than chance at predicting student college enrollment. 




#### Figure 3B 

Post-secondary STEM degree 

```{r, message = FALSE}
fig_3b_data <- els_complete %>% 
   filter(post_sec_stem == 1 | post_sec_stem == 0) %>% 
   mutate(as.factor(post_sec_stem)) 

# build ROC curves for number of STEM courses, math t scores, and STEM course GPA 
stem_degree1 = roc(fig_3b_data$post_sec_stem, fig_3b_data$no_stem_courses, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=1, xaxs="i", yaxs="i", main = "ROC curve for predicting STEM degree - Num. STEM Courses")

stem_degree2 = roc(fig_3b_data$post_sec_stem, fig_3b_data$math_tscore, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=2, xaxs="i", yaxs="i", main = "ROC curve for predicting STEM degree - Math t score (2002)")


stem_degree3 = roc(fig_3b_data$post_sec_stem, fig_3b_data$stem_GPA, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=3, xaxs="i", yaxs="i", main = "ROC curve for predicting STEM degree - STEM GPA")

```


Results for the ROC curves plotted in Figure 3B indicate that Number of STEM courses was the best predictor of whether or not students obtained a postsecondary STEM degree. Results also indicated that math t score predicted whether students obtained a STEM degree after high school. The table below shows the AUC values for each of the ROC curves above: 

```{r}
# print AUC values and store to a vector
auc_fig3b <- c(stem_degree1$auc, stem_degree2$auc, stem_degree3$auc) 

# store predictor names in a vector
predictor_fig3b <- c("Number of STEM Courses", "Math t score (2002)", "STEM GPA")    

# combine vector into a data frame, rename columns, adjust decimal points, and sort desceding by top AUC

fig3b_table <- data.frame(cbind(predictor_fig3b, auc_fig3b)) 
colnames(fig3b_table) <- c("Predictor", "AUC") 

# roundabout convert from factor, have to go through character format first
fig3b_table$AUC <- as.numeric(as.character(fig3b_table$AUC)) 
fig3b_table %>% 
   dplyr::mutate_if(is.numeric, round, 2) 

```


Results for AUC values reported in the table above indicate that the number of STEM courses students took was the best predictor of whether students received a postsecondary degree in a STEM field. 


#### Table 2: Significance of AUC Difference for College Enrollment Predictors and STEM Degree Predictors

The table below conducts difference tests between the predictors of college enrollment and STEM careers that were reported above to determine which of the predictors were significantly different from one another. The first code chunk reports results from Delong's test of AUC comparisons for the predictors of college enrollment. The second code chunk does the same for STEM degree. 


```{r}
# code below utilizes custom created function from above 
# that spits out results from Delong's test
roc_sig_diff(roc_enroll_1, roc_enroll_2) 
roc_sig_diff(roc_enroll_1, roc_enroll_3) 
roc_sig_diff(roc_enroll_2, roc_enroll_3) 

# create columns for table 
pred_list_1 <- c("GPA", "GPA", "Extra Curricular (2004)")   
pred_list_2 <- c("Extra Curricular (2004)", "AP", "AP")

# create z score column 
z_scores <- c(15.19, 29.85, 8.82)

# create p-value column 
p_values <- c("<.001", "<.001", "<.001")

# combine all columns and rename columns 

table_1 <- data.frame(cbind(pred_list_1, pred_list_2, z_scores, p_values)) 
table_1 %>% 
   rename("Predictor 1 " = pred_list_1, "Predictor 2" = pred_list_2, "Z" = z_scores, "p_value" = p_values)

```

Predictor comparisons for STEM degree. 

```{r}
roc_sig_diff(stem_degree1, stem_degree2) 
roc_sig_diff(stem_degree1, stem_degree3) 
roc_sig_diff(stem_degree2, stem_degree3) 

# create columns for table 
pred_list_1 <- c("Number of STEM Courses", "Number of STEM Courses", "Math t score (2002)")     
pred_list_2 <- c("Math t score (2002)", "GPA", "GPA")

# create z score column 
z_scores <- c(31.62,39.65,8.71)

# create p-value column 
p_values <- c("<.001", "<.01", "<.001")

# combine all columns and rename columns 

table_1 <- data.frame(cbind(pred_list_1, pred_list_2, z_scores, p_values)) 
table_1 %>% 
   rename("Predictor 1 " = pred_list_1, "Predictor 2" = pred_list_2, "Z" = z_scores, "p_value" = p_values)
```

These results indicate that all of the AUC values were significantly different from one another. The largest difference was between that of number of STEM courses taken and GPA. This finding supports trends visualized by the ROC curves in Figure 3B, where the plots clearly indicate that number of STEM courses taken significantly outperformed student GPA on the prediction task. 




# Part II


# Part III 

#### Provide a 2-3 page single spaced brief research proposal in which you argue for and justify the use of ROC AUC accuracy analysis and/or regression trees applied to a research topic that you are interested in. Please address the following questions in this order as you apply your new knowledge of these techniques (feel free to write this part in MS Word or similar and copy/paste into the markdown)

*a. What is the purpose of your study? *
	
	The purpose of this study is to apply CART analysis to predict which employees are likely to voluntarily leave their job. By using machine learning (ML), this study will train an ML model on prior employee turnover records to produce turnover likelihood scores for current employees. In addition, through the use of ROC AUC analysis and regression tree models (CART), this study will identify the strongest predictors of voluntary turnover. 

*b. Is there any research literature and theory that supports this argument? How so? *

   Past literature suggests that numerous variables are related to turnover decisions. Due to the complexity behind turnover decisions, it is beyond the scope of this research proposal to discuss them all. That being said, variables that have been shown to predict turnover include job satisfaction, burnout, perception of leadership, and disengagement at work. 

   To explore key predictors of voluntary turnover, this study hopes to analyze either the IBM HR Analytics Employee Attrition & Performance data set or the Work, Family and Health Network data set. The IBM data set contains attrition rate, as well as demographic and work environments variables, including age, business travel demands, gender, job satisfaction, environment satisfaction, education field, job role, income, overtime, percentage salary hike, tenure, training time, years in current role, relationship status, work life balance, distance from home, years since last promotion, and more. While the Work, Family and Health data set includes variables such as intention to quit, control over work schedule, burnout, job strain, low value work, work-family conflict, job satisfaction, and more. 

*c. Why is ROC AUC accuracy and/or regression trees (or both) a means to address this purpose? *
	
   CART analysis allows us to use the available data to identify the relationship between employees and work characteristics and turnover outcomes. By applying a CART analysis, the decision tree can then be applied to current employees to identify employees who are at risk of quitting. This analysis can help inform organizations which current employees might benefit from additional intervention or support to prevent attrition. Furthermore, the use of CART models will allow us to visualize variable importance in the prediction of turnover. Doing so will allow us to identify the most important predictors of turnover. In addition, CART models will allow us to identify the proportion of participants in our data set that are predicted to have specific levels of a given variable based on the variable cut point. For example, we anticipate that employee engagement will be a key predictor of turnover. CART will partition the employee engagement variable using gini index calculations to determine which level of engagement meaningfully separates those that turnover and those that do not turnover. For those that do turnover, we will want to know how many participants from our overall sample are in the sub-sets corresponding to specific levels of engagement. Doing so will contribute to our overall understanding of which variables predict turnover the best. 


*d. What would be the research question(s)? (To what extent…) *

This study hopes to identify the most important predictors of voluntary employee turnover and to identify current employees that are most at risk of turning over. 

*e. What type of data set would you need? Is there a data set you know of that would work? *
	
   We will need a data set with numerical and/or categorical variables that also contains historical turnover records for employees. As mentioned above, we will work with either the IBM HR Analytics Employee Attrition & Performance data set or the Work, Family and Health data set, both of which satisfy these requirements. The advantages of the IBM data set are 1) unlike the Work, Family and Health data set, it includes demographic variables, which had been found to relate to voluntary decisions 2) it contains turnover outcome, whereas the Work, Family and Health data set only measures intention to quit. On the other hand, the Work, Family and Health data set contains various psychological and work environment variables. Most importantly, the Work, Family and Health data set is real, whereas the IBM data set is fictional. 

*f. What types of data would you be looking for? *

We can use continuous and categorical variables as predictors. Turnover will be a binary variable. 

*g. Provide the generalized equation for the relevant underlying mathematical functions and a brief narrative in which you specify the type of calculation following the examples from the readings. *
	
In CART, the data are split into sub-nodes in each decision node based on the best predictor and its threshold value. CART algorithm splits subsequent sub-nodes with the help of the Gini or entropy indices.

According to Bulut and Desjardins (2021):

“When building a classification tree, either the Gini index or the entropy is typically used to evaluate the quality of a particular split, as they are more sensitive to the changes in the splits than the classification error rate. Typically, the Gini index is better for minimizing mis-classification, while the Entropy is better for exploratory analysis.

Gini Index is calculated as follows: 

```{r pressure, echo=FALSE, fig.cap="A caption", out.width = '100%'}
knitr::include_graphics("gini_index.png")
```
where KK represents the number of classes. This is essentially a measure of total variance across the KK classes. A small Gini index indicates that a node contains predominantly observations from a single class (Bulut & Desjardins, 2021). 

Entropy can be calculated as follows: 

```{r pressure, echo=FALSE, fig.cap="A caption", out.width = '100%'}
knitr::include_graphics("entropy_equation.png")
```




*h. What do you think you would find? *

   We believe we will find which employees are at risk of voluntarily leaving their job and the pattern of variables associated with this risk. The specific variables will depend on the data set we pick. 
 
*i. Why would this be important? What would be the implications for this research domain? *
	
   Employee turnover is a workplace outcome that has significantly interested researchers and practitioners for decades due to the high cost and negative effects associated with turnover. For example, recruiting for vacant positions is time intensive and on-boarding new hires is costly. By applying CART analysis to predict which employees are at risk of quitting, we intent to contribute to this rich and important area of research in which organizations can benefit.



test new GitHub PAT 
```{r}

```



