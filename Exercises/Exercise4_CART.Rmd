---
title: "Exercise 4"
author: "Nilima Ajaikumar, Hagay Jalon & Gian Zlupko"
date: "2022-11-14"
output: html_document
---

```{r message = FALSE, warning = FALSE}
library(tidyverse) 
library(xlsx) 
library(pROC) 
library(OptimalCutpoints) # for dealing with cutoff point
library(naniar) # replaces missing data to NA
```


# Part I: NECS Data 

For the first part of our Exercise 4, we are recreating the figures and tables published in Bowers & Zhou (2019). Our code and results for this section are organized as follows. First, we load and clean the NCES data. Then, we provide the code, documentation, and interpretation for Tables 1-3 and Figures 1-3 from Bowers & Zhou (2019) in the order in which they appear in the article. 

#### Import Data 

The following steps were implemented to access data from NCES' online repository. 


```{r}
setwd("/Users/gianzlupko/Desktop/ORLA 6541 Data Science/ORLA_6541_Applied_Data_Science/NCES_Data") 

# Load R Data File
load("els_full_data.rdata")

# simplify name of data frame 
els_full_data <- els_02_12_byf3pststu_v1_0


# variables that we would like to keep 

keepvars <- c(
   "STU_ID",
   "F2EVERDO", # Dropout
   "BYP52E", # Absent*
   "BYS24F", # Suspension*
   "BYP51", # Misbehavior*
   "BYTXMSTD", # Math t score (2002) - lowercase in the data
   "BYS42", # Extracurricular activities (2002) hours/wk
   "BYTXRSTD", # Reading t score (2002)* - lowercase in the data
   "F2PS0601", # College enrollment
   "F1RGPP2", # GPA
   "F1S27", # Extracurricular activities (2004) hours/wk
   "BYS33A", # AP
   "F3TZSTEM1CRED", # Postsecondary STEM degree
   "F3TZSTEM1TOT", # Number of STEM Courses
   "F3TZSTEM2GPA", # STEM course GPA
   "F3STEMOCCCUR" # Hard STEM career
)

# select subset of variables that were used in Bowers & Zhou (2019)
# also apply renaming to make the data readable 
els_clean <- els_full_data %>% 
  select(STU_ID, F2EVERDO, BYP52E, BYS24F, BYP51, bytxmstd, BYS42, bytxrstd,
         F2PS0601, F1RGPP2, F1S27, BYS33A, F3TZSTEM1CRED, F3TZSTEM1TOT,
         F3TZSTEM2GPA, F3STEMOCCCUR) %>%
  rename(student_ID = STU_ID, drop_out = F2EVERDO, absent = BYP52E, suspension = BYS24F, 
         misbehavior = BYP51, math_tscore = bytxmstd, extra_curr_2002 = BYS42, 
         reading_tscore = bytxrstd, college_enroll = F2PS0601, GPA = F1RGPP2, extra_curr_2004 = F1S27, AP = BYS33A, post_sec_stem = F3TZSTEM1CRED, no_stem_courses = F3TZSTEM1TOT, stem_GPA = F3TZSTEM2GPA, hard_stem_career = F3STEMOCCCUR)   

# inspect cleaning 
els_clean


# finally, create the feature engineered flags that Bowers & Zhou also tested to look at 
# the impact of the potential implication of one or more 'flags' or common indicators of 
# student drop out 
# the flags include: absent, suspension math_tscore in the 1st percentile, and misbehavior 

els_vars <- els_clean %>%
  mutate(flag_00 = ifelse(rowSums(select(., c(3:6)), na.rm = T) >= 1, 1, 0), 
         flag_01 = ifelse(absent == 1 | suspension == 1 | math_tscore == 1 | misbehavior == 1, 1,0), flag_04 = ifelse(absent == 1 & suspension == 1 & math_tscore == 1 & misbehavior == 1, 1, 0))

```

Remove missing data in the data set that are stored as -9, -8, -4, -1

```{r}
library(naniar)
els_complete <- replace_with_na_if(els_vars,
                                   .predicate = is.numeric,
                                   condition = ~.x < 0)

# Create the math t-score variable following Bowers' CART markdown 

els_complete <- els_complete %>% 
  mutate(math_t_score = ifelse(math_tscore < 44.065, 1, 0), 
         reading_t_score = ifelse(reading_tscore < 43.64, 1, 0))


# finally, view summary of clean variables 
summary(els_complete) 
```


Following Bowers & Zhou (2019), the first table that we create below is Figure 1, which presents a confusion table that specifies common metrics used in machine learning to evaluate prediction performance. 



### Table 1: Confusion Table for Calculating Contingency Proportions 


```{r}

fig_1_stats <- c("Accuracy", "Precision", "Sensitivity (Recall / True-positive Proportion",
                  "Specificity (True-negative Proportion", "1-Specificity (False-positive Proportion", "Kapp")

fig_1_equations <- c("(a + d) / N", 
                     "a / (a + b)", 
                     "a / (a + c)", 
                     "d / (b + d)", 
                     "b / (b + d)", 
                     "(Accuracy - R) / (1 - R)")

# bind columns 
fig_1 <- data.frame(cbind(fig_1_stats, fig_1_equations)) 
colnames(fig_1) <- c("Metric", "Equation")
fig_1

```




### Figures 2A and 2B 

Figure A depicts a ROC plot that utilizes predictors used by Balfanz et al.  (2007) and Figure B uses predictors selected by Bowers & Zhou (2019). 


Figure 2A
```{r, message = FALSE}

# ROC for math t-score
roc1 = roc(els_complete$drop_out, els_complete$math_t_score, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=1, xaxs="i", yaxs="i", main = "ROC curves for predicting dropout")

# ROC for one flag 
roc2 = roc(els_complete$drop_out, els_complete$flag_01, plot=TRUE, add=TRUE, percent=roc1$percent, lty=2)

# ROC for any number of flags 
roc3 = roc(els_complete$drop_out, els_complete$flag_00, plot=TRUE, add=TRUE, percent=roc1$percent, lty=3)

# ROC for all four
roc4 = roc(els_complete$drop_out, els_complete$flag_04, plot=TRUE, add=TRUE, percent=roc1$percent, lty=4)

# ROC for suspension 
roc5 = roc(els_complete$drop_out, els_complete$suspension, plot=TRUE, add=TRUE, percent=roc1$percent, lty=5)

# ROC for misbehavior
roc6 = roc(els_complete$drop_out, els_complete$misbehavior, plot=TRUE, add=TRUE, percent=roc1$percent, lty=6)

# ROC for absent
roc7 = roc(els_complete$drop_out, els_complete$absent, plot=TRUE, add=TRUE, percent=roc1$percent, lty=7)

# legend for the plot 
legend("bottomright", legend=c("Math t score (2002)","Any No. Flags","All Four Flags","Suspension", "Misbehavior", "Absent"), lty=c(1,2,3,4,5,6,7), lwd=2)

```


Figure 2B: 
```{r, message = FALSE}

# ROC for math t-score
roc8 = roc(els_complete$drop_out, els_complete$math_t_score, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=7, xaxs="i", yaxs="i", main = "ROC curves for predicting dropout")

# ROC for reading t score   
roc9 = roc(els_complete$drop_out, els_complete$reading_t_score, plot=TRUE, add=TRUE, percent=roc1$percent, lty=8)

# ROC for absent 
roc10 = roc(els_complete$drop_out, els_complete$absent, plot=TRUE, add=TRUE, percent=roc1$percent, lty=9)

# ROC for suspension 
roc11 = roc(els_complete$drop_out, els_complete$absent, plot=TRUE, add=TRUE, percent=roc1$percent, lty=10)

# ROC for suspension 
roc12 = roc(els_complete$drop_out, els_complete$extra_curr_2002, plot=TRUE, add=TRUE, percent=roc1$percent, lty=11)


# legend for the plot 
legend("bottomright", legend=c("Math t score (2002)", "Reading t score (2002)", "Extrac. activities (2002)", "Absence", "Suspension"), lty=c(7,8,9,10,11), lwd=2)
  
  
```

Figure 2A and 2B depict ROC curves for key variables used to predict high school drop out. All of the predictors in Figure 2B predicted drop out better than chance. This result can be seen by visually inspecting each ROC curve and their distance from the diagonal line in the center of the plot, which indicates a random guess of 0.5. In contrast to Figure 2B, some of the predictors visualized in Figure 2A did not perform better than chance at predicting drop out. In particular, results in Figure 2A demonstrate that any number of flags performed worse than a random guess and all four flags performed about equivalent to a random guess in predictive capacity. 



##### AUC Values Corresponding with Figure 2A and 2B 

Below, we create the data table that is pictured below Figures 2A and 2B in Bowers & Zhou (2019) to show the AUC values that correspond with their respective ROC curves. 

Table under 2A: 
```{r}
# print AUC values and store to a vector
auc_fig2a <- c(roc1$auc, roc2$auc, roc3$auc, roc4$auc, roc5$auc, roc6$auc, roc7$auc) 

# store predictor names in a vector
predictor_fig2a <- c("Math t score (2002)", "Any one flag", "Any number of flags", "All four flags", "Suspension", 
                     "Misbehavior", "Absent")  

# combine vector into a data frame, rename columns, adjust decimal points, and sort desceding by top AUC

fig2a_table <- data.frame(cbind(predictor_fig2a, auc_fig2a)) 
colnames(fig2a_table) <- c("Predictor", "AUC") 

# roundabout convert from factor, have to go through character format first
fig2a_table$AUC <- as.numeric(as.character(fig2a_table$AUC)) 

fig2a_table %>% 
   dplyr::mutate_if(is.numeric, round, 2) 

```

Table under 2B: 
```{r}

# print AUC values and store to a vector
auc_fig2b <- c(roc8$auc, roc9$auc, roc10$auc, roc11$auc, roc12$auc) 

# store predictor names in a vector
predictor_fig2b <- c("Math t score (2002)", "Reading t score (2002)", "Exac. activities (2002)", 
                     "Absence", "Suspension") 

# combine vector into a data frame, rename columns, adjust decimal points, and sort desceding by top AUC

fig2b_table <- data.frame(cbind(predictor_fig2b, auc_fig2b)) 
colnames(fig2b_table) <- c("Predictor", "AUC") 

# roundabout convert from factor, have to go through character format first
fig2b_table$AUC <- as.numeric(as.character(fig2b_table$AUC)) 

fig2b_table %>% 
   dplyr::mutate_if(is.numeric, round, 2) 
```


Results from tables corresponding with Figures 2A and 2B indicated that math t score (2002) was the best predictor of high school drop out. Other predictors that performed well in predicting drop out were absences and involvement in extracurricular activities. 


#### Table 1: Significance of AUC Difference for Predictors of Continuous Dropout 

In our recreation of Table 1 below, we present results from a Delong test of the difference of two correlated ROC curves. Large Z scores and small p-values (below the conventional p < .05) indicate that the area under the respective curves is significantly different. For our table, we compared each predictor to math t score (2002) which was the predictor with the best AUC value observed on the current data. 

```{r}

# custom function to extra Z scores and p-values 
roc_sig_diff <- function(x, y) { 
   
test1 <- roc.test(x,y) 
print(test1$p.value) 
print(test1$statistic) 
   
   }

# cycle through all comparisons needed to build the table: 
roc_sig_diff(roc1, roc2)  
roc_sig_diff(roc1, roc3)  
roc_sig_diff(roc1, roc4)  
roc_sig_diff(roc1, roc5)  
roc_sig_diff(roc1, roc6)  
roc_sig_diff(roc1, roc7)  

# create columns for table 

pred_list_1 <- c("Math t score (2002)", "Math t score (2002)", "Math t score (2002)",
                 "Math t score (2002)", "Math t score (2002)", "Math t score (2002)")  

pred_list_2 <- c("One Flag", "Any number of flags", "All four flags", "Suspension", "Misbehavior", 
                 "Absence")

# create z score column 

z_scores <- c(26.78, 23.85, 23.85, 8.55, 6.45, 0.62)

# create p-value column 
p_values <- c("<.001","<.001", "<.001", "<.001", "0.53", "0.61")


# combine all columns and rename columns 

table_1 <- data.frame(cbind(pred_list_1, pred_list_2, z_scores, p_values)) 
table_1 %>% 
   rename("Predictor 1 " = pred_list_1, "Predictor 2" = pred_list_2, "Z" = z_scores, "p_value" = p_values)
```



Results in Table 1 show that math t score (2002) performed significantly better at predicting dropout than one flag, any number of flags, all four flags, and suspension. In contrast, the results also demonstrated that math t score did not have a significantly different AUC than misbehavior and absence.


### Figure 3: ROC Curves for Predicting College Enrollment and Postsecondary STEM Degree 

Figure 3A
```{r, message = FALSE}

# filter data to only include two values for college enroll: 0 (No), and 1 (Yes)
fig_3_data <- els_complete %>% 
   filter(college_enroll == 1 | college_enroll == 0) 

# ROC curves for GPA, extracurriculars, and AP 5 
# 'roc_enroll'... get it?.... couldn't resist...

roc_enroll_1 = roc(fig_3_data$college_enroll, fig_3_data$GPA, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=12, xaxs="i", yaxs="i", main = "ROC curve for predicting college enrollment - GPA")

roc_enroll_2 = roc(fig_3_data$college_enroll, fig_3_data$extra_curr_2004, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=13, xaxs="i", yaxs="i", main = "ROC curve for predicting college enrollment - Extra Curriculars")


roc_enroll_3 = roc(fig_3_data$college_enroll, fig_3_data$AP, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=14, xaxs="i", yaxs="i", main = "ROC curve for predicting college enrollment - AP")

```

The table below shows the AUC values for each of the ROC curves above: 

```{r}

# print AUC values and store to a vector
auc_fig3a <- c(roc_enroll_1$auc, roc_enroll_2$auc, roc_enroll_3$auc) 

# store predictor names in a vector
predictor_fig3a <- c("GPA", "Extra Curriculars", "AP")     

# combine vector into a data frame, rename columns, adjust decimal points, and sort descending by top AUC

fig3a_table <- data.frame(cbind(predictor_fig3a, auc_fig3a)) 
colnames(fig3a_table) <- c("Predictor", "AUC") 

# roundabout convert from factor, have to go through character format first
fig3a_table$AUC <- as.numeric(as.character(fig3a_table$AUC)) 
fig3a_table %>% 
   dplyr::mutate_if(is.numeric, round, 2) 

```

The AUC values reported in the table indicate that GPA was the best predictor of college enrollment, followed by students' involvement in extra curricular activities. Finally, AP performed only slightly better than chance at predicting student college enrollment. 




#### Figure 3B 

Post-secondary STEM degree 

```{r, message = FALSE}
fig_3b_data <- els_complete %>% 
   filter(post_sec_stem == 1 | post_sec_stem == 0) %>% 
   mutate(as.factor(post_sec_stem)) 

# build ROC curves for number of STEM courses, math t scores, and STEM course GPA 
stem_degree1 = roc(fig_3b_data$post_sec_stem, fig_3b_data$no_stem_courses, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=1, xaxs="i", yaxs="i", main = "ROC curve for predicting STEM degree - Num. STEM Courses")

stem_degree2 = roc(fig_3b_data$post_sec_stem, fig_3b_data$math_tscore, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=2, xaxs="i", yaxs="i", main = "ROC curve for predicting STEM degree - Math t score (2002)")


stem_degree3 = roc(fig_3b_data$post_sec_stem, fig_3b_data$stem_GPA, legacy.axes=TRUE, asp=FALSE, plot=TRUE, grid=FALSE, lty=3, xaxs="i", yaxs="i", main = "ROC curve for predicting STEM degree - STEM GPA")

```


Results for the ROC curves plotted in Figure 3B indicate that Number of STEM courses was the best predictor of whether or not students obtained a postsecondary STEM degree. Results also indicated that math t score predicted whether students obtained a STEM degree after high school. The table below shows the AUC values for each of the ROC curves above: 

```{r}
# print AUC values and store to a vector
auc_fig3b <- c(stem_degree1$auc, stem_degree2$auc, stem_degree3$auc) 

# store predictor names in a vector
predictor_fig3b <- c("Number of STEM Courses", "Math t score (2002)", "STEM GPA")    

# combine vector into a data frame, rename columns, adjust decimal points, and sort desceding by top AUC

fig3b_table <- data.frame(cbind(predictor_fig3b, auc_fig3b)) 
colnames(fig3b_table) <- c("Predictor", "AUC") 

# roundabout convert from factor, have to go through character format first
fig3b_table$AUC <- as.numeric(as.character(fig3b_table$AUC)) 
fig3b_table %>% 
   dplyr::mutate_if(is.numeric, round, 2) 

```


Results for AUC values reported in the table above indicate that the number of STEM courses students took was the best predictor of whether students received a postsecondary degree in a STEM field. 


#### Table 2: Significance of AUC Difference for College Enrollment Predictors and STEM Degree Predictors

The table below conducts difference tests between the predictors of college enrollment and STEM careers that were reported above to determine which of the predictors were significantly different from one another. The first code chunk reports results from Delong's test of AUC comparisons for the predictors of college enrollment. The second code chunk does the same for STEM degree. 


```{r}
# code below utilizes custom created function from above 
# that spits out results from Delong's test
roc_sig_diff(roc_enroll_1, roc_enroll_2) 
roc_sig_diff(roc_enroll_1, roc_enroll_3) 
roc_sig_diff(roc_enroll_2, roc_enroll_3) 

# create columns for table 
pred_list_1 <- c("GPA", "GPA", "Extra Curricular (2004)")   
pred_list_2 <- c("Extra Curricular (2004)", "AP", "AP")

# create z score column 
z_scores <- c(15.19, 29.85, 8.82)

# create p-value column 
p_values <- c("<.001", "<.001", "<.001")

# combine all columns and rename columns 

table_1 <- data.frame(cbind(pred_list_1, pred_list_2, z_scores, p_values)) 
table_1 %>% 
   rename("Predictor 1 " = pred_list_1, "Predictor 2" = pred_list_2, "Z" = z_scores, "p_value" = p_values)

```

Predictor comparisons for STEM degree. 

```{r}
roc_sig_diff(stem_degree1, stem_degree2) 
roc_sig_diff(stem_degree1, stem_degree3) 
roc_sig_diff(stem_degree2, stem_degree3) 

# create columns for table 
pred_list_1 <- c("Number of STEM Courses", "Number of STEM Courses", "Math t score (2002)")     
pred_list_2 <- c("Math t score (2002)", "GPA", "GPA")

# create z score column 
z_scores <- c(31.62,39.65,8.71)

# create p-value column 
p_values <- c("<.001", "<.01", "<.001")

# combine all columns and rename columns 

table_1 <- data.frame(cbind(pred_list_1, pred_list_2, z_scores, p_values)) 
table_1 %>% 
   rename("Predictor 1 " = pred_list_1, "Predictor 2" = pred_list_2, "Z" = z_scores, "p_value" = p_values)
```

These results indicate that all of the AUC values were significantly different from one another. The largest difference was between that of number of STEM courses taken and GPA. This finding supports trends visualized by the ROC curves in Figure 3B, where the plots clearly indicate that number of STEM courses taken significantly outperformed student GPA on the prediction task. 


















